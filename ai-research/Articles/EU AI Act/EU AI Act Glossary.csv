term,summary,description
EU AI Act,"First comprehensive AI legal framework","The European Union's Artificial Intelligence Act is the world's first binding horizontal regulation for AI systems. It establishes a risk-based classification system with mandatory requirements for high-risk AI, prohibitions on certain practices, and transparency obligations. Entered into force August 2024 with phased implementation through 2027."
GPAI,"General-Purpose AI foundation models","General-Purpose AI models are AI systems trained on broad data capable of performing a wide range of tasks they were not specifically designed for (e.g., GPT-4, Claude, Gemini). Under the EU AI Act, GPAI providers have specific obligations including technical documentation, copyright policies, and training data summaries."
NIST AI RMF,"US voluntary AI risk framework","The National Institute of Standards and Technology AI Risk Management Framework provides voluntary guidance for organizations to manage AI risks throughout the AI lifecycle. Unlike the EU AI Act, it emphasizes flexible, consensus-driven best practices rather than mandatory compliance requirements."
NIS 2,"EU cybersecurity directive","Network and Information Security Directive 2 is EU legislation establishing cybersecurity risk management and incident reporting requirements for critical infrastructure sectors. It overlaps with the EU AI Act for organizations deploying AI in essential services, creating a 'dual compliance burden.'"
DORA,"EU financial sector ICT regulation","The Digital Operational Resilience Act is EU regulation requiring financial entities to implement comprehensive ICT risk management, incident reporting, and third-party risk oversight. Financial institutions using AI must comply with both DORA and EU AI Act requirements."
FRIA,"Mandatory rights impact assessment","Fundamental Rights Impact Assessment is a mandatory evaluation required before deploying high-risk AI systems. It assesses potential impacts on fundamental rights including privacy, non-discrimination, and human dignity. Required for law enforcement use of real-time biometric identification."
Annex I,"Regulated product legislation list","Annex I of the EU AI Act lists existing EU harmonization legislation (medical devices, machinery, toys, etc.) where products require third-party conformity assessment. AI systems that are safety components of these products automatically qualify as high-risk."
Annex III,"High-risk AI use case categories","Annex III defines eight sensitive areas where AI systems are classified as high-risk: biometrics, critical infrastructure, education, employment, essential services, law enforcement, migration/asylum, and administration of justice. Systems in these areas require conformity assessments and human oversight."
RBI,"Remote biometric identification","Remote Biometric Identification refers to AI systems that identify individuals at a distance by comparing biometric data against reference databases. Real-time RBI in public spaces for law enforcement is prohibited under Article 5, with narrow exceptions for serious threats requiring judicial authorization."
Conformity Assessment,"Pre-market compliance verification","Formal process to verify an AI system meets all applicable EU AI Act requirements before market placement. For high-risk systems, this includes technical documentation, quality management systems, risk management, and depending on the category, may require third-party notified body involvement."
Profiling,"Automated personal data analysis","Automated processing of personal data to evaluate or predict aspects of a natural person's life, including behavior, reliability, location, movements, health, or preferences. Any Annex III system performing profiling is automatically classified as high-risk with no derogation possible."
Systemic Risk,"Large-scale AI impact potential","Risk designation for GPAI models that could have significant negative impact on public health, safety, security, fundamental rights, or society at large. Triggered by training compute exceeding 10²⁵ FLOPs or high-impact capabilities. Requires enhanced obligations including adversarial testing and incident reporting."
FLOPs,"AI training compute measure","Floating Point Operations—the standard measure of computational power used to train AI models. The EU AI Act uses FLOP thresholds to classify GPAI: >10²³ FLOPs indicates GPAI status; >10²⁵ FLOPs triggers presumed systemic risk classification."
DUAA,"UK data access legislation","Data (Use and Access) Act 2025—UK legislation that diverges from EU GDPR approach, streamlining data sharing requirements and favoring agile, sector-led AI supervision rather than the EU's prescriptive horizontal regulation."
