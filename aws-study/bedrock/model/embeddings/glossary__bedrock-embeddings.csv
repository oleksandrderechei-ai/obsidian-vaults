Term,Summary,Description
"Embeddings","Vector representations of data","Numerical representations of text, images, or documents in a high-dimensional space where semantically similar items are placed closer together. Used for semantic search, RAG, and classification."
"Vector","Array of numbers representing meaning","A mathematical object consisting of an ordered list of numbers (dimensions) that represents the semantic meaning of input data. E.g., a 1024-dimensional vector has 1024 numbers."
"Semantic Search","Meaning-based search","Search technique that finds results based on conceptual meaning rather than exact keyword matching. Uses embeddings to compare query and document similarity."
"RAG","Retrieval-Augmented Generation","Architecture pattern that retrieves relevant context from a knowledge base using embeddings, then passes it to an LLM to generate informed responses. Reduces hallucinations."
"Cosine Similarity","Angle-based similarity measure","Mathematical measure of similarity between two vectors based on the angle between them. Ranges from -1 (opposite) to 1 (identical). Common for embedding comparison."
"Hamming Distance","Bit-difference similarity measure","Similarity metric for binary embeddings that counts the number of positions where bits differ. Faster to compute than cosine similarity."
"Dimensions","Number of values in a vector","The count of numbers in an embedding vector. Higher dimensions (1024, 1536) capture more semantic nuance but require more storage. Lower (256, 512) are more efficient."
"Float32 Embeddings","Full-precision embeddings","Standard embedding format using 32-bit floating-point numbers per dimension. Maximum precision but highest storage cost (4 bytes per dimension)."
"Binary Embeddings","1-bit compressed embeddings","Compact embedding format using 1 bit per dimension instead of 32 bits. 32x smaller storage but ~5-10% lower retrieval accuracy. Good for high-volume search."
"Int8 Embeddings","8-bit integer embeddings","Quantized embedding format using 8-bit integers. 4x smaller than float32 with minimal quality loss (~2-3%). Good balance of efficiency and accuracy."
"Multimodal Embeddings","Cross-modality vectors","Embeddings that represent both text and images in the same vector space, enabling search across modalities. E.g., find images using text queries."
"Input Type","Cohere embedding mode selector","Parameter for Cohere models specifying the embedding purpose: search_document (indexing), search_query (querying), classification, or clustering. Affects token prepending."
"search_document","Indexing mode for Cohere","Input type for Cohere Embed models used when encoding documents for storage in a vector database. Adds special tokens optimized for retrieval."
"search_query","Query mode for Cohere","Input type for Cohere Embed models used when encoding user queries for search. Adds special tokens optimized for matching against indexed documents."
"Normalization","Vector length standardization","Process of scaling embedding vectors to unit length (L2 norm = 1). Enables consistent cosine similarity calculations. Most embedding APIs normalize by default."
"Context Window","Maximum input token limit","The maximum number of tokens an embedding model can process in a single request. Cohere v4: 128K, Titan V2: 8K, Cohere v3: 512 tokens."
"Chunking","Splitting documents for embedding","Process of dividing large documents into smaller segments for individual embedding. Optimal chunk size depends on model context limit and retrieval granularity."
"Vector Store","Database for embeddings","Specialized database optimized for storing and searching embedding vectors. Examples: OpenSearch, pgvector, Pinecone, Redis, MongoDB Atlas."
"Knowledge Base","Managed RAG infrastructure","AWS Bedrock service that automates document ingestion, chunking, embedding, vector storage, and retrieval. Integrates with multiple vector stores."
"Reranking","Re-scoring retrieved results","Second-stage process that re-scores initial retrieval results using a more accurate model (e.g., Cohere Rerank 3.5) to improve final ranking quality."
"Cohere Embed v4","Latest Cohere embedding model","Multimodal embedding model supporting 128K context, configurable dimensions (256-1536), interleaved text+image, and multiple embedding types (float, int8, binary)."
"Cohere Embed v3","Previous Cohere embedding model","Text and image embedding model with 1024 fixed dimensions, 512 token context. Available in English and Multilingual (100+ languages) variants."
"Titan Text Embeddings V2","Amazon's text embedding model","AWS-native text embedding model with configurable dimensions (256-1024), 8K context, binary embedding support. Widest regional availability (20+ regions)."
"Titan Multimodal Embeddings","Amazon's multimodal embedding","AWS-native embedding model supporting text and images in the same vector space. Configurable dimensions (256, 384, 1024)."
"Nova Multimodal Embeddings","Amazon's latest multimodal model","Advanced embedding model supporting text, image, audio, and video in unified vector space. Model ID: amazon.nova-2-multimodal-embeddings-v1:0."
"Cross-region Inference","Multi-region embedding routing","Bedrock feature routing embedding requests across regions for higher availability. Cohere v4 supports 24+ regions via cross-region inference."
"Recall@K","Retrieval accuracy metric","Percentage of relevant items found in the top K results. E.g., Recall@10 = 95% means 95% of relevant docs appear in top 10. Binary embeddings: ~88% vs float: ~95%."
"MRR","Mean Reciprocal Rank","Retrieval quality metric measuring average of reciprocal ranks of first relevant result. Higher = relevant items appear earlier. Float: ~0.85, Binary: ~0.75."
"nDCG","Normalized Discounted Cumulative Gain","Ranking quality metric considering both relevance and position. Penalizes relevant items appearing lower. Float: ~0.90, Binary: ~0.80 at K=10."
"Two-Stage Retrieval","Efficient search architecture","Pattern using binary embeddings for fast initial retrieval (recall), then float embeddings or reranker for precise final ranking (precision). Balances cost and quality."
"Embedding Types","Vector format options","Output formats for embeddings: float (32-bit), int8 (8-bit signed), uint8 (8-bit unsigned), binary (1-bit signed), ubinary (1-bit unsigned). Trade precision for storage."
"Output Dimension","Configurable vector size","Parameter to select embedding vector length. Cohere v4: 256/512/1024/1536. Titan V2: 256/512/1024. Lower = efficient, higher = accurate."
"TwelveLabs Marengo Embed","Video-native embedding model","Multimodal embedding model specialized for video understanding. Generates multiple vectors per video capturing visual, audio, and temporal dimensions. Marengo 3.0 supports 4 hours/6GB video, 36 languages."
"Async Inference","Asynchronous model invocation","Inference mode for long-running operations like video processing. Request is submitted, model processes in background, results retrieved later. Required for TwelveLabs video embeddings."
"Video Embedding","Vector representation of video content","Numerical representation of video that captures visual scenes, actions, objects, audio, and temporal relationships. Enables semantic video search using text or image queries."
"Cross-Modal Search","Search across different modalities","Ability to query one modality (e.g., text) and retrieve results from another (e.g., video). TwelveLabs Marengo maps text, images, and video to shared vector space."
"Temporal Intelligence","Time-aware understanding","AI capability to understand events, actions, and changes over time in video content. Key differentiator for video embedding models vs static image embeddings."
