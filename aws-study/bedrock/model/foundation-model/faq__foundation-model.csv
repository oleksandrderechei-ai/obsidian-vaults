Question,Answer,Tags
"What is a Foundation Model?","A large neural network trained on massive, generalized datasets capable of performing a wide variety of tasks out of the box. Used as a starting point for building AI applications quickly and cost-effectively rather than training from scratch.","General,Concepts,Priority High"
"Does my data leave AWS when using Bedrock?","No. All inference happens within AWS infrastructure. Your prompts and outputs never leave AWS and are not shared with model providers like Anthropic or Meta.","Data Privacy,Security,Priority High"
"Are my prompts used to train foundation models?","No. AWS explicitly states that your inputs (prompts) and outputs are NOT used to train the base foundation models. Your company's data never improves the models.","Data Privacy,Training,Priority High"
"Does Bedrock log my prompts by default?","No. By default, Bedrock does not log your prompt text. If you require logs for auditing, you must explicitly enable Model Invocation Logging and configure it to send data to your own S3 bucket or CloudWatch.","Data Privacy,Logging,Priority Medium"
"What is the difference between On-Demand and Provisioned Throughput?","On-Demand: Pay only for tokens processed, shared model pool, like Uber. Provisioned Throughput: Reserved dedicated capacity, pay hourly 24/7 regardless of usage, like a private driver.","Deployment,Pricing,Priority High"
"What is a token and how does pricing work?","A token is a chunk of text (typically 3-4 characters or a word) that models process. You pay per 1,000 input tokens and per 1,000 output tokens. Prices vary by model.","Pricing,Concepts,Priority High"
"What is a context window?","The maximum number of tokens a model can process in a single request. Larger windows allow processing longer documents. E.g., Claude: 200K tokens, Nova Pro: 300K tokens.","Concepts,Model Selection,Priority Medium"
"What is hallucination and how do I prevent it?","Hallucination is when a model generates information that sounds correct but is factually wrong. Mitigate with RAG (external knowledge), guardrails, validation, and testing on representative data.","Challenges,Best Practices,Priority High"
"What is RAG (Retrieval Augmented Generation)?","A technique that retrieves relevant external knowledge from your data sources and provides it to the model to improve accuracy and reduce hallucinations. Bedrock Knowledge Bases provides built-in RAG.","Techniques,Concepts,Priority High"
"Should I fine-tune or use prompt engineering?","Start with prompt engineering - it's often more effective and requires no training. Fine-tune only when prompt engineering isn't sufficient and you have high-quality domain-specific data.","Best Practices,Techniques,Priority Medium"
"How do I choose between Claude, Nova, and Llama?","Consider: Task complexity (Claude for advanced reasoning), cost (Nova for budget), latency (Haiku/Nova Micro for speed), licensing (Llama for open-source needs), and compliance (regional availability).","Model Selection,Best Practices,Priority High"
"What encryption does Bedrock use?","Data is encrypted in transit (TLS 1.2+) and at rest. You can use Customer Managed Keys (AWS KMS) for additional control over encryption of data in Knowledge Bases or Agents.","Security,Compliance,Priority Medium"
"Can I use Bedrock with VPC isolation?","Yes. Use AWS PrivateLink (VPC Endpoints) to access Bedrock without traversing the public internet. This provides full VPC isolation for sensitive workloads.","Security,Architecture,Priority Medium"
"What is Cross-Region Inference?","A Bedrock feature that routes requests across multiple regions for higher throughput (3x) and availability (auto-failover). Trade-off: data may process in any configured region.","Architecture,Deployment,Priority Medium"
"What compliance certifications does Bedrock support?","Bedrock supports HIPAA, GDPR, SOC 2, and FedRAMP High. Check specific model and region availability for your compliance requirements.","Compliance,Security,Priority High"
"What is the Bedrock Runtime?","The AWS-managed infrastructure layer that hosts foundation models. Completely separate from your AWS account. Handles model deployment, scaling, and inference processing.","Architecture,Concepts,Priority Low"
"How does Bedrock handle third-party models like Claude?","AWS creates escrow accounts where third-party provider software runs. The provider's code executes there, but they cannot access your logs or data. Full isolation is maintained.","Architecture,Data Privacy,Priority Medium"
"What are Guardrails in Bedrock?","Safety and policy controls that filter harmful content, enforce policies, and ensure model outputs meet safety requirements. Configurable for content filtering, PII redaction, and topic blocking.","Features,Security,Priority Medium"
"What is few-shot learning?","Providing examples in your prompt to help the model understand the desired output format or task. No retraining required - the model learns from examples in context.","Techniques,Concepts,Priority Low"
"What is streaming and when should I use it?","Streaming delivers model output tokens as they're generated rather than waiting for the complete response. Use for chat interfaces and real-time applications to improve perceived latency.","Features,Best Practices,Priority Low"
"What are the main cost drivers for foundation models?","Most cost comes from inference (running the model), not training. Track token usage, use appropriate service tiers (Priority/Standard/Flex), and consider batch processing for 50% discount.","Pricing,Best Practices,Priority Medium"
"Can I deploy foundation models on my own infrastructure?","Open-source models like Llama can be self-hosted via SageMaker. Proprietary models (Claude, GPT-4) are only available through managed services. Bedrock provides fully managed access without infrastructure management.","Deployment,Model Selection,Priority Low"
